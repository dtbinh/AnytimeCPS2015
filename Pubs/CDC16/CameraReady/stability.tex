
\begin{theorem}[Stability]
	\label{thm:stability}
Given an equilibrium point $x_e \in X_0 \subset \iT(Z)$ of the nonlinear dynamics \eqref{eq:generic NLMPC}, Algorithm \ref{alg:RMPC} stabilizes the nonlinear system to an invariant set around $x_e$.
\end{theorem}

\begin{proof}
Let $T$ be the diffeomorphism mapping $x$ to $z$ from feedback linearization, and set $z_e = T(x_e)$. 
Since $x_e$ is an equilibrium point, $z_e=0$.
%By a change of variables $z' = z - T(x_e)$, stabilizing the linear dynamics (with state $z'$) to 0 implies stabilizing the nonlinear dynamics to $x_e$.
Recall that $Q$ and $Q_f$ of  \eqref{eq:nom mpc} are positive semi-definite and that $R$ is positive definite,  so that the optimal cost $J^*(\nz_{k})$ is a positive definite function of $\nz_{k}$, and that the terminal weight in \eqref{eq:nom mpc} is equivalent to the infinite horizon cost (by our choice of $Q_f$). 
Finally Thm.  \ref{th:robust_feas} guarantees that the tail of the input sequence computed at $k$ is admissible at time $k+1$. 
Therefore it is a standard result that the optimal cost $J^{*}({\nz}_{k})$ is non-increasing in $k$ and that $0$ is a stable equilibrium for the closed-loop linear system (e.g., see \cite{CannonK15MPC} ). 
Moreover, the terminal set $P_f$ is a robust invariant set of the $z$ dynamics containing 0 (see Section \ref{sec:Constraints}).
Therefore Algorithm \ref{alg:RMPC} stabilizes the nominal state $\nz$ to $P_f$ from anywhere in $Z_0$, and the true (linearized) state $z$ to an invariant set $Z_{inv}$ around $0$, and the nonlinear state $x$ to the invariant set $X_{inv} = T^{-1}(Z_{inv})$.
Therefore Algorithm \ref{alg:RMPC} drives $x$ to $X_{inv}$ from anywhere in $X_0 \subset \iT(Z)$.
\end{proof}