\section{Approximation and control}
\label{sec:examples}
We implemented the smooth approximation to the semantics of MTL, and tested it on several examples.

\subsection{Approximation error }
\label{sec: ex apx error}
\begin{figure}[t]
\centering
\includegraphics[width=0.45\textwidth]{figures/RobustnessError_corrected_scissored}
\vspace{-5pt}
\caption{{\small Robustness approximation error against formula horizon, evaluated on 1000 randomly generated trajectories for Example \ref{ex:toyproblem}. Unless noted, the systems are 2D. Color in online version.}}
\vspace{-10pt}
\label{fig:sample result}
\end{figure}

We evaluated the robustness $\robf$ and its approximation $\srobf$ for five formulae.
The horizon $N$ of each formula is varied, and at each value of $N$ we generate 1000 trajectories of system $x_{k+1} = x_k+u_k$ with input and state saturation, by feeding it random input sequences.
Fig. \ref{fig:sample result} shows the Root Mean Square (RMSE) of the approximation, $\sqrt{(1/1000)\sum_{\sstraj}(\robf(\sstraj)-\srobf(\sstraj))^2}$, and variance bars around it. 
As seen, the approximation errors and their variances are small, showing the accuracy and stability of the smooth approximation.
Note that while the RMSE  increased with the system dimension ($4^{th}$ formula in Fig.~\ref{fig:sample result}), it was observed that the relative error remained very small i.e. the increase in error is explained by an increase in the robustness's magnitude. 

%, with $hrz(\formula_i) = N$. $P_1$ and $P_2$ are atomic propositions for state being in two different polyhedra.
%Each formula is of the form $\formula_i = \always_{[0:N-1]} \psi$, where $N$ is the length of the trajectory.
%Thus $hrz(\formula_i)  = N$.
% of varying lengths $N$, so we can  examine the error's variation with the horizon.
%All formulas use the atomic propositions $P_1 \defeq x \in [-1,1]^n$ and $P_2 \defeq x\in [2,2.5]^n$, where $n = 2,3$ is the dimension of the system.
%The state-space is $[-5,5]^n$ and the input set is $\inpSet = [-0.3,0.3]^n$. 

\subsection{Robustness maximization for control}
\label{sec:toy example}
Problem $P_\rob$ given in \eqref{eq:general_ctrl} is solved by replacing the true robustness $\robf$ by its smooth approximation $\srobf$, and setting $\epsilon_{\text{min}}$ to the value of the smooth approximation error.
We thus obtain Problem $P_{\srob}$. 
This approach is labeled \textit{Smooth Operator} (SOP).

\textbf{Optimization solver.}
Problem $P_{\srob}$ is solved using Sequential Quadratic Programming (SQP).
SQP solves constrained non-linear optimization problems by creating a sequence of quadratic approximations to the problem and solving these approximate problems.
SQP enjoys various convergence-to-(local)-optima properties~\cite[Section 2.9]{Polak97_Optim}.
For example, for SQP to converge to a strict local minimum (a minimum that is strictly smaller than any objective function value in an open neighborhood around it), it suffices that 
1) all constraint functions be twice Lipschitz continuously differentiable. 
In our case, this includes function $f$ in \eqref{eq:general ctrl obj}, and the problems we solve satisfy this requirement.
And, 
2) at points in the search space that lie on the boundary of the inequality-feasible set
% (where the inequality constraints are satisfied with equality), 
there exists a search direction towards the interior of the feasible set that does not violate the equality constraints~\cite[Assumption 2.9.1]{Polak97_Optim}. 
%(the so-called Mangasarian-Fromowitz constraint qualification) .
This is also true in our case since our equality constraints come from the dynamics and are always enforced for any $\mathbf{u}$.

\textbf{Solver initialization}.
To initialize SQP when solving $P_{\srob}$ (i.e., to give it a starting value for $\mathbf{u}$), we can either solve an inexpensive feasibility linear program with constraints \eqref{eq:general ctrl dyn}-\eqref{eq:general ctrl U}, 
or generate a random input sequence respecting $u_t \in U$. 
The resulting initial trajectory could violate the specification (as it does in every example we study in this paper) and it is only required to satisfy the dynamics and state constraints.

\textbf{Comparisons to BluSTL.}
The tool BluSTL implements the MILP approach of ~\cite{Raman14_MPCSTL} and is used in the experiments.
It has two modes of operation: mode (B) or \textit{Boolean}, which aims at satisfying the specification without maximizing its robustness, and mode (R) or \textit{Robust}, which attempts to maximize robustness. 
The proposed SOP method optimizes robustness and so naturally runs in mode (R).
SOP emulates mode (B) by terminating the optimization as soon as $\srobf \geq \epsilon_{\text{Meyer}}$, which implies $\rob_{\formula} \geq 0$. $\epsilon_{\text{Meyer}}$ can be computed explicitly using the approach in the online report \cite{PantAM17_SmoothOpTechRpt}.

\input{toyExample}
\input{nonlinear}
%\input{toyFalse}
