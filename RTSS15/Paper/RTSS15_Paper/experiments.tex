\section{Case Study: Real-time feedback control of a hexrotor with contract based estimation and robust control}
\label{sec:experiments}

\subsection{Experimental setup}
To evaluate our methodology on a real platform, we applied it to a hexrotor with the Odroid U3 as a computation platform and running the Robot Operating System (ROS) in Ubuntu. For the evaluation, the hexrotor is tasked with repeatedly following a given circular trajectory.
As can be seen in Fig.~\ref{fig:time_ecdf}, the visual odometry algorithm can occcasionaly take a long time to get a pose estimate. In our formulation in section \ref{robustMPC} we have assumed that the estimator satisfies the $(\delta, \epsilon)$ contract requested by the controller. Thus, to ensure that the estimator fulfills the contract and the mathematical guarantees that our RAMPC formulation provides hold, instead of using the visual odometry algorithm to fly the robot, we injected delays and errors into the measurements from the Vicon system. These delays and errors were selected from the $(\delta,\epsilon)$ curve obtained by profiling the SVO algorithm (see Section \ref{sec:visual_odometry}).
The hexrotor flies using these pose estimates and our Robust Model Predictive Algorithm for both the position control of the hexrotor and setting the time deadline for the next estimate. The RAMPC, is coded in CVXGEN \cite{} and the generated C-Code is integrated in the ROS module for position control of the hexrotor. The set computations for the feasible sets are done offline in MATLAB and then used in CVXGEN as Polyhedron type constraints ($Hx \le g$). 
%For the contract based perception and estimation algorithm we use the FAST corner detector (as in section \ref{}) providing measurements to an Unscented Kalman Filter that also uses measurements from an Inertial Measurement Unit (IMU) to provide a state estimate for the control algorithm to use.
Later in this section we show how our approach dynamically schedules different modes of the contract-based perception and estimation algorithm at run-time and also controls the dynamic system in an energy-efficient way while providing good tracking performance. In the evaluation subsection we will compare our results to a baseline Model Predictive Control algorithm that does not leverage co-design and operates at fixed ($\delta,\epsilon$) points of the perception/estimation algorithm which provides a state estimate to the controller.

\todo[author=KM,inline]{Do we want an architecture diagram of the way the hexrotor is controlled using ROS?}
\todo[author=YVP,inline]{Yes, the trajectory generator to MPC/RAMPC to low level part would be good to show and make for a nice fig.}
%The control performance, as measured by a function that factors in the error in following the flight path and the cost of control, is shown in Fig.~\ref{fig:CostAndModes}.
%(The details of this cost function are given in Section \ref{formulation}).


\subsection{Profiling the perception and estimation pipeline}

Recall that in section \ref{robustMPC}, the control algorithm needs the profiled ($\delta,\epsilon$) curve for the perception and estimation algorithm. In our experimental setup, we need the performance of the SVO algorithm to formulate the RAMPC for control of the hexrotor. Figure \ref{fig:svo_error_delay} shows the bound on estimation error and the $90^{th}$ percentile execution times for a different number of maximum corners in the SVO algorithm through extensive flying over a relatively feature-rich environment (Figure \ref{fig:hexrotor}). The estimation error is computed with the help of ground truth obtained through the Vicon motion capture system. We profiled the performance for the same trajectory with different settings of the odometry offline by logging images and IMU data in-flight, and then running the visual odometry code on the Odroid-U3 offline.
This accurately recreates the in-flight environment that is present for the visual odometry algorithm and this profiling is then used online for making in-flight decisions by the control algorithm.

Also needed for the control optimization as stated in equation \ref{eq:tractableOptim} is a measure of the power consumption by the visual odometry while at different settings on maximum number of corner. This is obtained again by running the visual odometry code offline for different knob settings and measuring the power consumed by the Odroid to perform these computations. Power measurements are made using the Odroid Smart Power meter \cite{OdroidSmartPower}, which measures consumption at 10Hz to milliwatt precision. We measure the power consumption of the entire Odroid board, including CPU and DRAM power consumption. To avoid the physical challenges of fitting the power meter onto our hexrotor platform, we measure the power consumption of the Odroid board on the ground, running the same controller and vision workloads as it does during flight as explained above. Since the profiling of power is done offline with other peripherals plugged into the odroid (e.g. A monitor and keyboard), we measure the idle power of the Odroid and subtract that from the power measurements when the SVO algorithm is running on it in different modes. This gives us a more accurate measure of the workload the visual odometry task is responsible for. This offline profiling now allows us to formulate the co-design problem for the hexrotor and experimentally evaluate our methods.


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\columnwidth]{figures/time_ecdf_millisec.pdf}
  \caption{Cumulative distribution of profiled execution times for visual odometry running on the Odroid-U3 for varying maximum number of corners from the SVO algorithm.}
  \label{fig:time_ecdf}
\end{figure}



\input{experimentalEval}

\input{experimentalResults}
