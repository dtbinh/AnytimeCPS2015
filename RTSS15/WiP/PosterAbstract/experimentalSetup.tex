\section{Experiment setup}

In this work, we focus on the particular case of autonomous corridor navigation. For this purpose we use the vanishing point algorithm [??] and PID control to maintain heading parallel to the corridor and stay in the middle of it. We implement our algorithm on a $1/10^{th}$ scale car we developed. This section covers the hardware, the algorithm, and the hardware level knobs which affect the performance of the closed loop system and energy consumption of the computation platform.

\subsection{The hardware}

For our experiments, we converted a Radio controlled Traxxas Rally car into an autonomous robot \ref{}[fig], similar to the ones used in \cite{}[MITsertac]. The computation platform is a NVIDIA Jetson TK1. The Jetson has a quad-core ARM Cortex-A15 CPU and a NVIDIA Kepler GPU. This setup allows us to schedule tasks on the CPU or GPU while observing the effect of this on power consumption and timing performance of the algorithm. More details on this are covered in a later section. The Jetson runs Ubuntu for Tegra as the operating system, and the algorithms are implemented using ROS /cite{}[ROS]. The control signals for the drive and steer motor on the platform are generated by a Teensy 3.1 microcontroller which runs a ROS node which converts the continuous output of the control algorithm to the PWM signal which acts as an input to the motor controller on the Traxxas. Finally, the perception algorithm, which is the vanishing point algorithm, gets images from a front facing Point Grey Firefly MV camera which is capable of recording color images at upto a resolution of 752x480 pixels and upto a frame rate of 60 FPS. Additional sensors are also present in the form of a Lidar, optical flow and a 9-dof IMU, but are not used in this study.

\subsection{Vanishing point based corridor navigation}

The Vanishing point algorithm \cite{}[?] has been used extensively in indoor settings for navigation corridors autonomously \cite{}[?][?]. Our experimental setup also relies on the Vanishing point algorithm, implement in OpenCV \cite{}[opencv] to provide feedback to the control algorithm. The vanishing point algorithm outputs the horizontal distance of the vanishing point from the center of the image frame, this feedback is used by the controller to orient the robot such that the distance of the vanishing point from the center of the image frame become zero, i.e. the robot is aligned with the corridor. 

For brevity, we will not explain in detail the workings of the vanishing point algorithm (the interested reader can refer to \cite{}[?]), but will focus on the major computational tasks that comprise the vanishing point algorithm. As shown in figure \ref{}[?], the major computational tasks of the vanishing point algorithm are (sequentially)

\begin{itemize}
\item Blur: A Gaussian blur is applied on the image for de-noising.
\item Edge detection: We use the Canny Edge detector \cite{}[?] to find edges in the image.
\item Hough Transform: In our implementation, the Hough transform is used to detect lines in the image.
\item Random sample consensus (RANSAC): RANSAC is used to find the lines which best describe the parallel lines which represent the sides of the corridor. These lines intersect in the image plane at the Vanishing Point.
\end{itemize}

\subsection{Exploiting hardware level knobs}
With the vanishing point algorithm, we can execute the Blur, the edge detection and the Hough transform on either the CPU or the GPU. RANSAC runs fast enough to not have a signifcant impact on the total execution time, so we do not consider running it on the GPU.
Execution on the GPU results, in general, in a speed-up over the CPU but at a cost of higher power draw from the Jetson. Additionally, on the Jetson, we can control the performance of the CPU and GPU by changing the clock frequencies at which they operate. This gives us multi-dimensional knobs on the hardware level that we can control to trade-off computation speed and power consumption by the Jetson.




