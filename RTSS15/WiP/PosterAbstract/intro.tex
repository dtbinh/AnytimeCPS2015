\section{Motivation}
\label{sec:motivation}

Autonomous vehicles promise significant benefits to society, from reduced accident rates to greater mobility for the elderly. 
The biggest challenge in the design of autonomous vehicles comes from the uncertainty of the environment in which they will operate. 
Their control algorithms must be able to cope with driving events that occur on widely ranging time scales. 
For example, relaxed rural driving can accommodate planning actions every few seconds, while imminent collision avoidance requires planning and actuation on the order of a few milliseconds.
Thus `real-time' performance will imply different things depending on the context. 

A second, related, challenge is that the perception algorithms on-board these vehicles (like object detection based on video feed) must handle a very large amount of data, leading to increased power consumption. 
This is especially true for autonomous vehicles (AVs) since they carry multiple sensors (cameras, LIDAR, radars, ultrasound radars, etc) whose data must be processed in real-time to avoid accidents.

As a result of the variability in the environment, the control and perception systems are over-engineered to operate as if the worst-case conditions always hold. 
This results in unnecessarily high power consumption from the computation platform. 
For example, an autonomous research vehicle has two 4KW power inverters dedicated to computation.
Compare this to the average power drawn by the drivetrain of a small electric vehicle, which is 2.4KW, when modeled  in ADVISOR \cite{nreladvisor} going through the Urban Dynamometer Drive Cycle.
(The peak power draw in the same test is 30 KW).
It is also worth noting that over the past few decades, the power consumption of processors has increased by more than double, while battery energy density has only improved by about a quarter \cite{Lahiri}. 

In the current work, we explore the idea of trading-off computation time and power for quality of output, and how this trade-off affects \emph{control performance}.
We start from the observation that the best quality output from the perception algorithm is not always required for the system to achieve the desired control performance.
For example, the control objective might be to follow the center of a driving lane, and control performance is measured by the deviation from that center.
At slow speeds, poor quality of position estimate may be tolerated since it won't lead to excessive deviations from the center.
Therefore we focus on \emph{anytime perception algorithms} that have a pre-defined set of interruption times. 
In general, the earlier the algorithm is interrupted, the worse is the quality of its output. 
On the other hand, that quality may be sufficient for the control algorithm to achieve its goal.

In \cite{RTSS15} we proposed a way in which a standard perception algorithm can be turned into an anytime algorithm via off-line profiling, and thus can offer a time/power/quality trade-off.
We also designed a model predictive controller than can make use of the trade-off offered by the anytime perception algorithm.
To achieve the time/power/quality trade-off, we produced multiple versions of the perception algorithm.
Broadly speaking, a version that ran for longer produced a higher quality output. 

In this work, we turn our attention to achieving the time/power/control performance trade-off \emph{at a fixed level of output quality}, using \emph{platform-level} optimizations.
Even if the output quality of the perception algorithm is fixed, the \emph{speed} at which the output is computed affects control performance: in general, the longer the computation delay, the worse the control performance.
Specifically, we work with an autonomous car $1/10^{th}$ the size of a regular car (Fig. \ref{fig:traxxas}).
\begin{figure}[t]
	\centering
	\includegraphics[scale=0.08]{traxxas.jpg}
	\caption{Traxxas autonomous car with camera.}
		\label{fig:traxxas}
\end{figure}  
It is equipped with a front facing monocular camera and runs the Vanishing Point perception algorithm \cite{VP1}. 
The on-board computation platform has both a CPU and GPU. 
More details of the experimental setup are in Section \ref{sec:experimentalSetup}.
The platform-level optimization divides the Vanishing Point algorithm into components, and decides whether to run each component on the CPU or GPU, and at what frequency.
The assignment to CPU or GPU is not static: every time the algorithm is executed, a different assignment may result, at a different frequency.
The assignment is dictated by the controller: based on off-line profiling of each processor's performance on each component, the controller decides what quality is currently acceptable while minimizing power consumption. 
The profiling is described in more detail in Section \ref{sec:profiling}.
In the present paper, we present initial results of partitioning the Vanishing Point algorithm and running different components on CPU and GPU, and at different frequencies.
We also provide the related power numbers, demonstrating that a meaningful difference in runtime and power consumption exists depending on the assignment and frequency.
In future work, we design a controller to make use of this and other optimizations, and relate the current results to the control algorithm.

